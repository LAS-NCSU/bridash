{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding Pew Public Opinion Data \n",
    "\n",
    "This file allows for the geocoding of the Pew Public Opinion Data (as it stands on June 6th with data from 2017-2021). \n",
    "\n",
    "Geocoding will occur at the country and administrative boundary 1 level. \n",
    "\n",
    "*Note: we have been forced to reconsider our geocoding scheme with the adoption of the Pew Public Opinion Data* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(path): \n",
    "    file = open(path, \"r\")\n",
    "    contents = file.read()\n",
    "    dictionary = json.loads(contents)\n",
    "    file.close()\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4449/583155433.py:1: DtypeWarning: Columns (5,6,8,9,10,11,12,13,17,32,52,55,56,57,59,61,62,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"pew_processed.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"pew_processed.csv\", index_col=0)\n",
    "countries = pd.read_csv(\"../../data_final/countries.csv\", dtype={'country_id':str}, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the names to a common value for searching for the geometry \n",
    "# grabs it from txt file for consistency of country naming conventions\n",
    "\n",
    "recipient_mapping = load_dict(\"../country_config.txt\")\n",
    "df['country'] = df['country'].replace(recipient_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocode Country Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking that all conventions of country naming is consistent. \n",
    "set(df['country']).difference(set(countries['country']))\n",
    "\n",
    "# an empty set means all countries are accounted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_map = dict(zip(countries['country'], countries['country_id']))\n",
    "df['country_id'] = df['country'].map(countries_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocode at the Regional Level \n",
    "\n",
    "### Utilize GeoBoundaries to grab up to date information on administrative boundaries\n",
    "\n",
    "Administrative boundaries courtesy of <a href= 'https://www.geoboundaries.org'>geoBoundaries</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following is an example of how to utilize the geoBoundaries API\n",
    "j = requests.get(\"https://www.geoboundaries.org/api/current/gbOpen/RUS/ADM1\")\n",
    "path = j.json()['gjDownloadURL']\n",
    "shape = requests.get(path).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = pd.json_normalize(\n",
    "    shape, \n",
    "    record_path = ['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a common variable name to use for matching with ADM1 versus NUTS2 Boundaries \n",
    "\n",
    "Countries using ADM1 should be marked with adm_region.    \n",
    "Countries using NUTS2 should be marked with nuts_region. \n",
    "\n",
    "Both will be run through independant sources to grab shapefiles. Regional codes will exported as a list of ADM1 boundaries which the data is attributed to.     \n",
    "*Note: This looks to increase granularity while ensuring standardization across datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a temporary dataset of locations\n",
    "region_temps = pd.DataFrame(columns = ['adm_temp', 'nuts_temp', 'temp_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for unique countries, things have to be classified with unique codes\n",
    "# build a filter. Add the filtered data to temp_temp. \n",
    "# Combine the information into the relevant 'adm_temp' or 'nuts_temp'. \n",
    "# once everything is combined. Transfer back to DF and check length and completeness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021 and 2020 \n",
    "# all based off of ADM codes\n",
    "filter_1 = (df['survey_year'] == 2021) | (df['survey_year'] == 2020)\n",
    "region_temps['adm_temp'] = df['region'].where(filter_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 \n",
    "filter_1 = (df['survey_year'] == 2019)\n",
    "\n",
    "region_temps['temp_temp'] = [x if pd.notna(x) else y for x, y in zip(df['region'].where(filter_1), df['stratum'].where(filter_1))]\n",
    "region_temps['adm_temp'] = region_temps['adm_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "# override with a qs5 value for Isreal\n",
    "filter_2 = (df['survey_year'] == 2019) & (df['country'] == 'Isreal')\n",
    "region_temps['temp_temp'] = df['qs5'].where(filter_2)\n",
    "region_temps['adm_temp'] = region_temps['temp_temp'].combine_first(region_temps['adm_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 \n",
    "\n",
    "# EU Nuts coded\n",
    "filter_1 = ((df['survey_year'] == 2018) & ((df['country'] == 'Greece') | \n",
    "                (df['country'] == 'Italy') | (df['country'] == 'Hungary') | (df['country'] == 'Poland')))\n",
    "region_temps['temp_temp'] = df['qs5'].where(filter_1)\n",
    "region_temps['nuts_temp'] = region_temps['nuts_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "# ADM coded from stratum\n",
    "filter_2 = ((df['survey_year'] == 2018) & ((df['country'] == 'Russia') | (df['country'] == 'India') | \n",
    "            (df['country'] == 'Philippines') | (df['country'] == 'Tunisia') | (df['country'] == 'Kenya') | \n",
    "            (df['country'] == 'South Africa') | (df['country'] == 'Argentina') | (df['country'] == 'Brazil') |\n",
    "            (df['country'] == 'Mexico') | (df['country'] == 'Nigeria')))\n",
    "region_temps['temp_temp'] = df['stratum'].where(filter_2)\n",
    "region_temps['adm_temp'] = region_temps['adm_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "# ADM coded from qs5\n",
    "filter_3 = ((df['survey_year'] == 2018) & ((df['country'] == 'Australia') | (df['country'] == 'Indonesia') | \n",
    "           (df['country'] == 'Japan') | (df['country'] == 'Israel')))\n",
    "region_temps['temp_temp'] = df['qs5'].where(filter_3)\n",
    "region_temps['adm_temp'] = region_temps['adm_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "# ADM coded from qs11\n",
    "filter_4 = ((df['survey_year'] == 2018) & ((df['country'] == 'Canada')))\n",
    "region_temps['temp_temp'] = df['qs11'].where(filter_4)\n",
    "region_temps['adm_temp'] = region_temps['adm_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "# NUTS coded from qs11\n",
    "filter_5 = ((df['survey_year'] == 2018) & ((df['country'] == 'France') | (df['country'] == 'Germany') \n",
    "                                          | (df['country'] == 'Netherlands') | (df['country'] == 'Spain') \n",
    "                                          | (df['country'] == 'Sweden') | (df['country'] == 'United Kingdom')))\n",
    "region_temps['temp_temp'] = df['qs11'].where(filter_5)\n",
    "region_temps['nuts_temp'] = region_temps['nuts_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "\n",
    "\n",
    "# TODO: missing values currently from westernized areas... look into                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017 \n",
    "\n",
    "# ADM coded in qs12\n",
    "filter_1 = ((df['survey_year'] == 2017) & ((df['country'] == 'Canada') | (df['country'] == 'Germany'))) \n",
    "region_temps['temp_temp'] = df['qs12'].where(filter_1)\n",
    "region_temps['adm_temp'] = region_temps['adm_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "# ADM coded in qs5\n",
    "filter_2 = ((df['survey_year'] == 2017) & ((df['country'] == 'Australia') | (df['country'] == 'Israel')\n",
    "           | (df['country'] == 'Venezuela'))) \n",
    "region_temps['temp_temp'] = df['qs5'].where(filter_2)\n",
    "region_temps['adm_temp'] = region_temps['adm_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "# ADM coded from stratum\n",
    "filter_3 = ((df['survey_year'] == 2017) & ((df['country'] == 'Mexico') | (df['country'] == 'Russia') \n",
    "            | (df['country'] == 'India') | (df['country'] == 'Indonesia') | (df['country'] == 'Philippines')\n",
    "            | (df['country'] == 'Argentina') | (df['country'] == 'Brazil') | (df['country'] == 'Chile')\n",
    "            | (df['country'] == 'Colombia') | (df['country'] == 'Ghana') | (df['country'] == 'Kenya') \n",
    "            | (df['country'] == 'Nigeria')  | (df['country'] == 'South Africa') | (df['country'] == 'Senegal')\n",
    "            | (df['country'] == 'Tunisia') | (df['country'] == 'Vietnam') | (df['country'] == 'Jordan') \n",
    "            | (df['country'] == 'Lebanon') | (df['country'] == 'Tanzania') | (df['country'] == 'Peru')))\n",
    "region_temps['temp_temp'] = df['stratum'].where(filter_3)\n",
    "region_temps['adm_temp'] = region_temps['adm_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "# EU Nuts coded\n",
    "filter_4 = ((df['survey_year'] == 2017) & ((df['country'] == 'Greece') | (df['country'] == 'Italy') | \n",
    "           (df['country'] == 'Hungary') | (df['country'] == 'Poland') | (df['country'] == 'Turkey'))) \n",
    "region_temps['temp_temp'] = df['stratum'].where(filter_4)\n",
    "region_temps['nuts_temp'] = region_temps['nuts_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "# ADM coded from qs11\n",
    "filter_5 = ((df['survey_year'] == 2017) & ((df['country'] == 'France') | (df['country'] == 'Netherlands') \n",
    "            | (df['country'] == 'South Korea') | (df['country'] == 'Spain') | (df['country'] == 'Sweden')\n",
    "            | (df['country'] == 'United Kingdom')))\n",
    "region_temps['temp_temp'] = df['qs11'].where(filter_5)\n",
    "region_temps['adm_temp'] = region_temps['adm_temp'].combine_first(region_temps['temp_temp'])\n",
    "\n",
    "\n",
    "\n",
    "# missing values from US/South Korea/UK/France/Netherlands/Spain/Sweden/Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override with US States for 2020-2017\n",
    "\n",
    "filter_1 = (df['country'] == 'United States')\n",
    "region_temps['temp_temp'] = df['state_us'].where(filter_1)\n",
    "region_temps['adm_temp'] = region_temps['temp_temp'].combine_first(region_temps['adm_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You still have 2984 variables missing\n"
     ]
    }
   ],
   "source": [
    "print(\"You still have \" + str(region_temps.shape[0] - region_temps['adm_temp'].combine_first(region_temps['nuts_temp']).value_counts().sum()) + \" variables missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>stratum</th>\n",
       "      <th>psu</th>\n",
       "      <th>qs5</th>\n",
       "      <th>qs6</th>\n",
       "      <th>qs8</th>\n",
       "      <th>qs11</th>\n",
       "      <th>qs12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>survey_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">France</th>\n",
       "      <th>2018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Germany</th>\n",
       "      <th>2018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <th>2021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <th>2017</th>\n",
       "      <td>0</td>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Netherlands</th>\n",
       "      <th>2018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Singapore</th>\n",
       "      <th>2021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Korea</th>\n",
       "      <th>2018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Spain</th>\n",
       "      <th>2018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sweden</th>\n",
       "      <th>2018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">United Kingdom</th>\n",
       "      <th>2018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            region  stratum  psu  qs5  qs6  qs8  qs11  qs12\n",
       "country        survey_year                                                 \n",
       "France         2018              0        0    0    0    0    0     0     0\n",
       "               2019              0        0    0    0    0   26     0     0\n",
       "               2020              0        0    0    0    0    0     0     0\n",
       "               2021              0        0    0    0    0    0     0     0\n",
       "Germany        2018              0        0    0    0    0    0     0     0\n",
       "               2019              0        0    0    0    0  226     0     0\n",
       "               2020              0        0    0    0    0    0     0     0\n",
       "               2021              0        0    0    0    0    0     0     0\n",
       "Italy          2021              0        0    0    0    0    0     0     0\n",
       "Japan          2017              0     1009    0  507  502    0     0     0\n",
       "Netherlands    2018              0        0    0    0    0    0     0     0\n",
       "               2020              0        0    0    0    0    0     0     0\n",
       "               2021              0        0    0    0    0    0     0     0\n",
       "Singapore      2021              0        0    0    0    0    0     0     0\n",
       "South Korea    2018              0        0    0    0    0    0     0     0\n",
       "Spain          2018              0        0    0    0    0    0     0     0\n",
       "               2019              0        0    0    0    0    2     0     0\n",
       "               2020              0        0    0    0    0    0     0     0\n",
       "               2021              0        0    0    0    0    0     0     0\n",
       "Sweden         2018              0        0    0    0    0    0     0     0\n",
       "               2021              0        0    0    0    0    0     0     0\n",
       "United Kingdom 2018              0        0    0    0    0    0     0     0\n",
       "               2019              0        0    0    0    0   17     0     0\n",
       "               2020              0        0    0    0    0    0     0     0\n",
       "               2021              0        0    0    0    0    0     0     0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run to see missing variables\n",
    "# use this query to explore a particular country/year further \n",
    "# df[(df['survey_year'] == 2017) & (df['country'] == 'Japan')][['region', 'stratum', 'psu', 'qs5', 'qs6', 'qs8', 'qs11', 'qs12']]\n",
    "\n",
    "# use this query to identify missing variables \n",
    "df[pd.isna(df['adm_region']) & pd.isna(df['nuts_region'])].groupby(['country', 'survey_year'])[['region', 'stratum', 'psu', 'qs5', 'qs6', 'qs8', 'qs11', 'qs12']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all adm_temp and nuts_temp values in the database for replacing \n",
    "df['adm_region'] = region_temps['adm_temp']\n",
    "df['nuts_region'] = region_temps['nuts_temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocoding Methodology\n",
    "\n",
    "We need to update Pew's data of regional locations to an ADM1 bound. The following method has been identified to create that pairing. \n",
    "\n",
    "- Utilize a countries ISO3 id to grab the json file of the ADM1 boundaries for each country. \n",
    "- Use fuzzy matching to identify the ADM1 boundaries that can automatically be matched with the correct shapefile. (Utilize a custom matching percent to get the best result) \n",
    "- Identify which regional locations were below your accuracy threshold, and create dictionaries to support the geocoding of those particular locations. *Note: more recent data is typically more accurate, know that they regional locations have changed across years and there will need to be some parsing for consistency*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example to identify the changes in regional location over time within pew\n",
    "# know that there is some ambiguity in ADM 1 to be grabbing\n",
    "# df.groupby('survey_year')['regional_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['regional_location_original'] = [x if pd.notna(x) else y for x,y in zip(df['adm_region'], df['nuts_region'])]\n",
    "\n",
    "# Fixing Cases for Groups \n",
    "\n",
    "df['adm_region'] = [x.title() if pd.notna(x) else x for x in df['adm_region']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Update Country Listings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_country(dff, name, mapping): \n",
    "    dff.loc[dff['country'] == name, 'regional_location'] = dff['regional_location'].replace(mapping)\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEXICO \n",
    "\n",
    "# Electoral regions are groupings of ADM1 \n",
    "# TODO: Map or create unique regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CANADA \n",
    "\n",
    "canada = {\n",
    "    'Montreal' : 'Quebec',\n",
    "    'Vancouver' : 'British Columbia', \n",
    "    'Toronto' : 'Ontario', \n",
    "    # 'Atlantic Region' : 'New Brunswick', 'Nova Scotia', 'Prince Edward Island'\n",
    "}\n",
    "\n",
    "df = update_country(df, 'Canada', canada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERU \n",
    "\n",
    "peru = {\n",
    "    'Junin' : 'Junín'\n",
    "}\n",
    "\n",
    "df = update_country(df, 'Peru', peru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARGENTINA \n",
    "\n",
    "# argen = {\n",
    "#     'amba' : 'Autonomous City of Buenos Aires', \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_boundary(iso3): \n",
    "    \n",
    "    j = requests.get(\"https://www.geoboundaries.org/api/current/gbOpen/\" + iso3 + \"/ADM1\")\n",
    "    try: \n",
    "        path = j.json()['gjDownloadURL']\n",
    "        shape = requests.get(path).json()\n",
    "\n",
    "        country_df = pd.json_normalize(\n",
    "                            shape, \n",
    "                            record_path = ['features'])\n",
    "\n",
    "        return country_df\n",
    "    \n",
    "    except: \n",
    "        print(\"The country \" + iso3 + \" is not available within geoboundaries.\")\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_adm(adm_df, entity_df, sim_threshold): \n",
    "\n",
    "    adm_dict = dict(zip(range(0, len(adm_df)), adm_df['properties.shapeName']))\n",
    "    entity_df['fuzzy_matching'] = [[fuzz.partial_ratio(x, y) for x in adm_df['properties.shapeName']] for y in entity_df['regional_location']]\n",
    "    entity_df['adm1'] = [adm_dict[x.index(max(x))] if max(x) > sim_threshold else \"Not found\" for x in entity_df['fuzzy_matching']]\n",
    "    \n",
    "    print(\"There are \" + str(len(entity_df[entity_df['adm1'] == 'Not found'])) + \" instances not identified\")\n",
    "    print(\"Here are the missing elements: \")\n",
    "    print(set(entity_df[entity_df['adm1'] == 'Not found']['regional_location']))\n",
    "    \n",
    "    \n",
    "    return dict(zip(entity_df['regional_location'], adm_df['properties.shapeName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mexico:\n",
      "There are 15 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Circunscripcion 2', 'Circunscripcion 1', 'Circunscripcion 4', 'Circunscripcion 3', 'Electoral Region 5', 'Electoral Region 4', 'Electoral Region 3', 'Circunscripción 5', 'Electoral Region 1', 'Circunscripción 2', 'Circunscripción 1', 'Circunscripción 4', 'Circunscripcion 5', 'Circunscripción 3', 'Electoral Region 2'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Canada:\n",
      "There are 2 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Refused', 'Atlantic Region'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Argentina:\n",
      "There are 10 instances not identified\n",
      "Here are the missing elements: \n",
      "{'North', 'Centro- Gran Rosario', 'Amba', 'Centro- La Plata', 'South', 'Sur', 'Centro- Mar Del Plata', 'Norte', 'Centro', 'Central'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Chile:\n",
      "There are 3 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Norte', 'Sur', 'Central'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Peru:\n",
      "There are 0 instances not identified\n",
      "Here are the missing elements: \n",
      "set()\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Brazil:\n",
      "There are 36 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Df Distrito Federal', '31-Mg', '25-Pb', '24-Rn', 'South', '27-Al', 'Northeast', '13-Am', '12-Ac/16-Ap/14-Rr/17-To', 'Pi Piaui', '53-Df', '22-Pi', 'North', 'Central West', '33-Rj', 'Município De Belo Horizonte (31-Mg)', '43-Rs', '51-Mt', '21-Ma', '26-Pe', '28-Se', '11-Ro', '41-Pr', '23-Ce', '35-Sp', 'Município De Salvador (29-Ba)', 'Pa Para', 'Ce Ceara', 'Go Goias', '29-Ba', '50-Ms', '32-Es', '42-Sc', '15-Pa', 'Southeast', '52-Go'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Colombia:\n",
      "There are 4 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Atlantica', 'Central', 'Oriental', 'Pacifica'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Venezuela:\n",
      "There are 6 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Centro Oeste', 'Noreste', 'Andes', 'Oeste', 'Sur', 'Central'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Ghana:\n",
      "There are 0 instances not identified\n",
      "Here are the missing elements: \n",
      "set()\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Senegal:\n",
      "There are 0 instances not identified\n",
      "Here are the missing elements: \n",
      "set()\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "United Kingdom:\n",
      "There are 155 instances not identified\n",
      "Here are the missing elements: \n",
      "{'150109', '150007', '150130', '150163', '150043', '150020', '150054', '150063', '150090', 'London', '150056', '150074', '150073', 'Ovre Norrland', '150015', '150138', '150147', '150042', '150032', '150146', '150173', '150096', '150171', '150022', '150004', '150165', '150150', '150112', '150066', '150051', '150136', '150142', '150012', '150016', '150140', '150156', '150019', '150017', '150060', '150070', '150092', '150161', '150100', '150087', '150044', '150067', '150103', '150143', '150145', '150048', '150084', '150065', '150097', '150008', '150170', '150107', '150164', '150069', '150095', '150139', '150057', '150159', '150115', '150123', '150106', '150013', '150049', '150168', '150141', '150133', '150052', '150086', '150172', '150050', '150031', '150010', '150006', '150099', '150152', '150104', '150108', '150045', '150154', '150105', '150035', '150080', '150128', '150162', '150151', '150089', '150153', '150079', '150037', '150058', '150014', '150061', '150127', '150018', '150155', '150055', '150091', '150101', '150116', '150126', '150117', 'Yorkshire And The Humber', '150072', '150157', '150047', '150160', '150149', '150030', '150121', '150102', '150120', '150169', '150036', '150093', '150071', '150113', '150085', '150009', '150094', '150011', '150114', '150118', '150034', '150039', '150028', '150131', '150053', '150129', '150137', '150068', '150005', '150088', '150029', '150024', 'Refused', '150122', '150148', '150110', '150021', '150027', '150119', '150040', '150002', '150124', '150025', '150078', '150076', '150158', '150033', '150046', '150023'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "New Zealand:\n",
      "There are 2 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Refused', 'Kansai'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Kenya:\n",
      "There are 13 instances not identified\n",
      "Here are the missing elements: \n",
      "{' Eastern', ' Nyanza', ' Rift Valley', 'Rift Valley', 'North Eastern', 'Coast', ' Central', ' Western', ' North Eastern', ' Coast', 'Western', 'Eastern', 'Central'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "South Africa:\n",
      "There are 0 instances not identified\n",
      "Here are the missing elements: \n",
      "set()\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Tanzania:\n",
      "There are 1 instances not identified\n",
      "Here are the missing elements: \n",
      "{' Mjini Magharibi'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Nigeria:\n",
      "There are 14 instances not identified\n",
      "Here are the missing elements: \n",
      "{'North East', 'North West', 'South East', ' South West', ' North East', 'South', 'North Central', 'South West', 'South South', ' South South', ' North Central', ' South East', ' North West', 'Middle Belt / North Central'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Tunisia:\n",
      "There are 7 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Kebilli', ' Gabes', 'Gabes', 'Bèja', ' Beja', 'Beja', ' Kebilli'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Greece:\n",
      "There are 25 instances not identified\n",
      "Here are the missing elements: \n",
      "{'El6 - Kentriki Ellada', 'El52', 'El3 - Attiki', 'El5 - Voreia Ellada', 'El65', 'El3', 'El63', 'El4 - Nisia Aigaiou, Kriti', 'El43', 'North Aegean', 'El64', 'Western Greece', 'West Macedonia', 'El54', 'Refused', 'West Greece', 'El61', 'Ionian Islands', 'El51', 'East Macedonia And Thrace', 'Central Macedonia', 'Bavaria', 'South Aegean', 'El53', 'Peloponnese'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Israel:\n",
      "There are 0 instances not identified\n",
      "Here are the missing elements: \n",
      "set()\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Jordan:\n",
      "There are 1 instances not identified\n",
      "Here are the missing elements: \n",
      "{\"Ma'An Governorate\"}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Lebanon:\n",
      "There are 36 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Zahle', 'Jbeil', \"Beirut-Marfa'A (Port)\", 'Al Shouf', 'Sour', \"Ba'Abda\", 'Miniyeh-Danniyeh', 'Tripoli', \"Beirut-Mazra'A\", 'Beirut-Bashoura', 'Beirut-Sayfeh', 'Keserwan', 'Batroun', 'Beirut-Rmeil', 'Bent Jbeil', 'Hermel', 'Beirut-Ashrafiyeh', 'Hasbaya', 'Alayh', 'West Bequaa', 'Saida', 'Becharre', 'Rashaya', 'Koura', 'Akkar', 'Zgharta', 'Jezzine', 'Beirut-Dar El Mreyseh', 'Beirut-Ras Beirut', 'Beirut-Msateybeh', 'Beirut-Zkak El Blat', \"Ba'Alback\", 'Beirut-Mina Al Hosen', 'Beirut-Mdawar', 'El Metn', 'Marjeyoun'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Turkey:\n",
      "There are 22 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Tr1', 'Tr8', 'Tr3', 'Trc', 'Guneydogu Anadolu', 'Tr2', 'Tr4', 'Akdeniz', 'Orta Anadolu', 'Bati Anadolu', 'Tr5', 'Dogu Marmara', 'Bati Karadeniz', 'Dogu Karadeniz', 'Tr6', 'Ortadogu Anadolu', 'Bati Marmara', 'Tr9', 'Ege', 'Tr7', 'Kuzeydogu Anadolu', 'Trb'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "United States:\n",
      "There are 2 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Midwest', 'Northeast'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "France:\n",
      "There are 109 instances not identified\n",
      "Here are the missing elements: \n",
      "{'120085', '120004', '120009', '120021', '120013', '120034', '120078', '120046', 'La Réunion', '120019', '120088', '120066', '120049', '120069', '120045', 'Picardie', '120027', '120072', 'Lorraine', 'Midi-Pyrénées', '120056', '120006', '120010', '120048', '120067', '120093', '120008', 'Alsace', '120023', 'Liege Province', 'Guyane', '120047', '120084', '120043', '120083', '120065', '120011', '120022', '120024', '120091', '120087', '120030', '120092', 'Mayotte', '120082', '120053', '120094', '120040', '120029', '120063', '120059', 'Limousin', '120096', 'Champagne-Ardenne', '120086', '120054', 'Poitou-Charentes', '120039', '120007', '120036', '120079', '120002', '120042', '120061', '120074', '120015', '120035', '120038', 'Corse', '120060', '120025', '120068', '120057', 'Pays-De-La-Loire', '120026', '120055', '120016', '120037', '120033', '120077', 'Languedoc-Roussillon', '120041', '120090', '120005', '120001', '120051', '120018', '120089', '120044', 'Nord-Pas-De-Calais', '120058', '120075', '120003', '120020', '120014', '120080', '120081', 'Centre-Val De Loire', '120062', 'Refused', '120032', '120076', 'Martinique', '120052', '120050', '120073', '120017', '120071', '120031'}\n",
      "--------------\n",
      "encoding adm1_id codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Belgium:\n",
      "There are 11 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Flemish Brabant Province', 'Alberta', 'Refused', 'Liege Province', 'Limburg Province', 'Antwerp Province', 'Luxembourg Province', 'Walloon Brabant Province', 'Hainaut Province', 'Don’T Know', 'Namur Province'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Germany:\n",
      "There are 247 instances not identified\n",
      "Here are the missing elements: \n",
      "{'130361', '130348', '130181', '130004', '130138', '130249', '130162', '130300', '130089', 'Saxony-Anhalt', '130385', '130135', '130278', '130111', '130371', '130101', '130247', '130265', '130139', '130332', '130110', '130030', '130064', '130152', '130080', '130073', '130187', '130063', '130370', '130191', '130364', '130012', '130074', '130009', '130108', '130376', '130274', '130055', '130180', '130272', '130242', '130188', '130090', '130373', '130390', '130357', '130308', '130194', '130301', '130052', '130121', '130142', 'Bavaria', '130022', '130178', '130327', '130193', '130126', '130164', '130087', '130034', '130075', '130176', '130141', '130351', '130013', '130219', '130241', '130240', '130117', '130290', '130056', '130130', '130210', '130354', '130041', '130318', '130137', '130263', '130343', '130203', '130359', '130019', '130150', '130047', '130001', '130157', '130312', '130118', '130292', '130159', '130374', '130006', '130070', '130380', '130032', '130289', '130084', '130309', '130167', '130273', '130156', 'Lower Saxony', 'Rhineland-Palatinate', '130316', '130297', '130072', '130037', '130325', '130270', '130344', '130146', '130015', '130192', '130140', '130044', '130043', '130018', '130358', '130328', '130319', '130068', '130100', '130054', '130227', '130221', '130069', '130127', '130010', '130199', '130023', '130189', '130020', '130163', '130062', '130217', '130119', '130112', '130113', '130123', '130008', '130303', '130253', '130205', '130340', '130161', '130136', '130243', '130131', '130104', '130398', 'North Rhine-Westphalia', '130026', '130336', '130306', '130031', '130048', '130133', '130066', '130124', '130045', '130036', '130280', '130237', '130105', '130058', '130195', '130046', '130148', '130051', '130216', '130231', '130171', '130321', '130079', '130184', '130096', 'Thuringia', '130076', '130200', '130042', '130248', '130236', '130352', '130235', '130029', '130346', '130383', '130244', '130049', '130039', '130266', '130286', '130177', '130050', '130295', '130211', '130088', '130154', '130335', '130085', '130206', '130102', '130214', '130134', '130067', '130060', '130160', 'Saxony', '130129', '130275', '130232', '130353', '130182', '130027', '130093', '130005', '130007', '130220', '130250', '130384', '130065', '130209', '130226', '130059', '130017', '130299', '130083', '130021', 'Refused', '130304', '130035', '130132', '130003', '130355', '130002', '130025', '130259', '130264', '130170', '130285', '130106', '130165', '130024', '130115', '130011', '130016'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Netherlands:\n",
      "There are 40 instances not identified\n",
      "Here are the missing elements: \n",
      "{'310007', '310032', '310036', '310031', '310024', '310005', '310040', '310021', '310013', 'Centro', '310008', '310037', '310023', '310034', '310016', '310009', '310012', '310004', '310003', 'Refused', '310025', '310035', '310006', '310027', '310018', '310001', '310038', '310002', '310029', '310014', '310030', '310011', '310033', '310017', '310022', '310019', '310020', '310015', '310039', '310028'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Czech Republic:\n",
      "There are 8 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Jihovychod (Cz06)', 'Severovychod (Cz05)', 'Moravskoslezsko (Cz08)', 'Jihozapad (Cz03)', 'Severozapad (Cz04)', 'Stredni Cechy (Cz02)', 'Praha (Cz01)', 'Stredni Morava (Cz07)'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Denmark:\n",
      "There are 3 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Refused', 'Don’T Know', 'Region Sjaelland'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Hungary:\n",
      "There are 13 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Great Plain And North', 'Central', 'Hu2 - Transdanubia', 'Hu22', 'Transdanubia', 'Hu1', 'Hu23', 'Hu21', 'Hu3 - Great Plain And North', 'Hu32', 'Hu33', 'Hu1 - Central Hungary', 'Hu31'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Italy:\n",
      "There are 22 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Itg - Insular Italy', 'Northwest', 'Iti - Central Italy', 'Itc- Northwest Italy', 'South', 'Itf', 'Nord-Ovest', 'Northeast', 'Centro', 'Itf - South Italy', 'Sud', 'Itg', 'Iti', 'Itc', 'Ith - Northeast Italy', 'Refused', 'Crete', 'Insular', 'Central', 'Ith', 'Isole', 'Nord-Est'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Poland:\n",
      "There are 18 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Pl1', 'Pl1 - Centralny', 'North', 'Pl5 - Poludniowo-Zachodni', 'Pl3 - Wschodni', 'North West', 'Pl6 - Pólnocny', 'South', 'South West', 'East', 'Pl6', 'Pl2', 'Pl4 - Pólnocno-Zachodni', 'Pl2 - Poludniowy', 'Pl3', 'Pl5', 'Pl4', 'Central'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Slovakia:\n",
      "There are 4 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Central Slovakia (Stredné Slovensko)', 'Bratislava Region', 'Western Slovakia (Západné Slovensko)', 'Eastern Slovakia (Východné Slovensko)'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Sweden:\n",
      "There are 29 instances not identified\n",
      "Here are the missing elements: \n",
      "{'550007', '550002', '550016', '550017', 'Norra Mellansverige', '550011', 'Mellersta Norrland', 'Ovre Norrland', '550001', '550004', '550021', 'Vastsverige', 'Smaland Med Oarna', '550014', '550013', '550018', '550012', '550009', '550020', '550003', '550006', '550008', 'Sydsverige', '550010', 'Principado De Asturias', '550015', 'Ostra Mellansverige', '550005', '550019'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Bulgaria:\n",
      "There are 6 instances not identified\n",
      "Here are the missing elements: \n",
      "{'North-East (Severoiztochen)', 'South-Central (Yuzhen Tsentralen)', 'South-East (Yugoiztochen)', 'North-West (Severozapaden)', 'North-Central (Severen Tsentralen)', 'South-West (Yugozapaden)'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Lithuania:\n",
      "There are 0 instances not identified\n",
      "Here are the missing elements: \n",
      "set()\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Ukraine:\n",
      "There are 6 instances not identified\n",
      "Here are the missing elements: \n",
      "{'North', 'Kiyv', 'South', 'Center', 'East', 'West'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "India:\n",
      "There are 4 instances not identified\n",
      "Here are the missing elements: \n",
      "{'South', 'East', 'North', 'Northeast'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Indonesia:\n",
      "There are 29 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Nusa Tenggara Barat [Western Lesser Sunda Islands]', 'Kalimantan Barat [West Borneo]', '[73] Sulawesi Selatan', '[64] Kalimantan Timur', 'Kalimantan Barat [Western Borneo]', '[35] Jawa Timur', '[32] Jawa Barat', '[33] Jawa Tengah', '[12] Sumatera Utara', 'Sulawesi Utara [Northern Sulawesi]', '[71] Sulawesi Utara', 'Sumatera Utara [Northern Sumatra]', '[13] Sumatera Barat', 'Jawa Barat [Western Java]', '[34] Di Yogyakarta', 'Kalimantan Selatan [South Borneo]', '[31] Dki Jakarta', '[52] Nusa Tenggara Barat', 'Sumatera Barat [Western Sumatra]', 'Kalimantan Timur [East Borneo]', '[53] Nusa Tenggara Timur', '[63] Kalimantan Selatan', 'Kalimantan Tengah [Central Borneo]', 'Nusa Tenggara Timur [East Lesser Sunda Islands]', 'Sumatera Selatan [Southern Sumatra]', '[16] Sumatera Selatan', '[61] Kalimantan Barat', 'Jawa Timur [Eastern Java]', '[62] Kalimantan Tengah'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Australia:\n",
      "There are 9 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Sydney', 'Dk/Refused', 'Adelaide', 'Melbourne', 'Refused', 'Hobart', 'Brisbane', 'Perth', 'Darwin'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Singapore:\n",
      "There are 7 instances not identified\n",
      "Here are the missing elements: \n",
      "{'North', 'Refused', 'North-East', 'East', 'Manawatu-Wanganui', 'Central', 'West'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Vietnam:\n",
      "There are 6 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Red River Delta', 'Central Highlands', 'Northern Midlands And Mountains', 'Southeast', 'Mekong River Delta', 'North And South Central Coast'}\n",
      "--------------\n",
      "encoding adm1_id codes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "China:\n",
      "There are 22 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Chunghwa County', 'Hsinchu City', 'Taitung County', 'Chiayi County', 'Chiayi City', 'Yunlin County', 'Nantou County', 'Kaohsiung City', 'Penghu County', 'Taoyuan City', 'Yilan County', 'Refused', 'Kinmen County', 'Miaoli County', 'Pingtung County', 'New Taipei City', 'Taipei City', 'Taichung City', 'Hualien County', 'Keelung City', 'Hsinchu County', 'Chungcheongbuk-Do'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Philippines:\n",
      "There are 12 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Visayas (Excl Cebu City)', 'City Of Antipolo (Balance Luzon)', 'Cebu City (Visayas)', 'Balance Luzon (Excl City Of Antipolo)', 'Kalookan City (Ncr)', 'Ncr', 'Quezon City (Ncr)', 'National Capital Region (Excl Quezon City, Manila City, And Kalookan City)', 'National Capital Region (Ncr)', 'Manila City (Ncr)', 'Mindanao (Excl Davao City)', 'Davao City (Mindanao)'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "South Korea:\n",
      "There are 6 instances not identified\n",
      "Here are the missing elements: \n",
      "{'Jeollabuk-Do', 'Jeollanam-Do', 'Gyeongsangnam-Do', 'Refused', 'Gyeongsangbuk-Do', 'East'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Japan:\n",
      "There are 57 instances not identified\n",
      "Here are the missing elements: \n",
      "{'230016', 'Chubu', '230031', '230008', '230038', '230019', 'Kansai', '230028', '230037', '230042', '230044', '230046', 'Perth', 'Shikoku', '230017', '230006', '230005', '230007', '230002', 'Dont Know', '230026', '230012', '230025', '230041', 'Kanto', '230032', '230034', '230036', '230009', '230030', '230040', '230013', '230018', '230021', 'Refused', '230003', '230022', '230020', '230043', '230039', 'Kyushu', '230011', '230027', 'Chugoku', '230010', 'Sapporo', '230001', '230045', '230035', '230033', '230023', '230029', \"Don'T Know/Refused \", 'Tohoku', '230004', '230024', '230014'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Russia:\n",
      "There are 14 instances not identified\n",
      "Here are the missing elements: \n",
      "{'North Caucasus', 'Southern', 'Siberia', 'Far East', 'Northwestern', 'South', 'North Western', 'Urals', 'Siberian', 'Central Region', 'Volga', 'Ural', 'Central', 'North-Western'}\n",
      "--------------\n",
      "encoding adm1_id codes\n",
      "\n",
      "Spain:\n",
      "There are 56 instances not identified\n",
      "Here are the missing elements: \n",
      "{'430008', '430038', '430016', '430042', '430033', '430055', '430028', '430002', '430037', '430041', '430050', '430031', '430047', '430036', '430059', '430015', '430023', 'Ciudad De Melilla', '430001', '430014', '430026', '430020', '430011', '430030', '430010', '430032', 'Ciudad De Ceuta', '430007', '430018', '430004', '430009', '430013', '430012', '430043', '430029', '430039', '430045', 'Refused', '430005', '430027', '430021', '430048', 'Noord-Holland', '430057', '430006', '430034', '430054', '430046', '430051', '430040', '430044', '430035', '430003', '430049', '430017', '430019'}\n",
      "--------------\n",
      "encoding adm1_id codes\n"
     ]
    }
   ],
   "source": [
    "for country in range(0, len(countries)): \n",
    "    \n",
    "    # find all the unique values of regional locations for the country of interest \n",
    "    all_loc = set(df[df['country'] == countries['country'][country]]['regional_location'])\n",
    "    all_loc.discard(np.nan)\n",
    "    unique_loc = pd.DataFrame(all_loc, columns = ['regional_location'])\n",
    "    if len(unique_loc) == 0: \n",
    "        # print(\"The country \" + countries['country'][country] + \" is not in Pew dataset.\")\n",
    "        continue \n",
    "        \n",
    "    # grab the geoBoundary for the country of interest \n",
    "    try: \n",
    "        shape = load_boundary(countries['iso3'][country])\n",
    "    except: \n",
    "        print(\"\\n\" + countries['country'][country] + \":\")\n",
    "        print(\"ERROR\")\n",
    "        continue\n",
    "\n",
    "    # get the ADM name for all of the regional locations\n",
    "    # ignore 'Refused' and 'DK' values. They will only have location at the country level coded. \n",
    "\n",
    "    # encode == True will go ahead and add the Adm1_id code to the dataframe. Its reccomended when testing the dataset\n",
    "    # you leave this as False\n",
    "    \n",
    "    print(\"\\n\" + countries['country'][country] + \":\")\n",
    "    dict_country = find_adm(shape, unique_loc, 80)\n",
    "    \n",
    "    print('--------------')\n",
    "    print('encoding adm1_id codes')\n",
    "    df['adm1'] = df['regional_location'].replace(dict_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Center \n",
    "\n",
    "Give it a name of a country to see:\n",
    "- the listing of years and common regional locations being displayed\n",
    "- the values of the ADM boundaries it is trying to match with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survey_year  regional_location\n",
       "2017         Central Region       282\n",
       "             Volga                198\n",
       "             Siberia              132\n",
       "             Northwestern          96\n",
       "             Southern              96\n",
       "             Ural                  84\n",
       "             North Caucasus        72\n",
       "             Far East              42\n",
       "2018         Volga                210\n",
       "             Central              190\n",
       "             Siberian             140\n",
       "             Southern              90\n",
       "             Urals                 90\n",
       "             Moscow                80\n",
       "             North Caucasus        60\n",
       "             North Western         60\n",
       "             Far East              40\n",
       "             St.Petersburg         40\n",
       "2019         Volga                226\n",
       "             Central              209\n",
       "             Siberia              128\n",
       "             South                 98\n",
       "             Moscow                90\n",
       "             Ural                  90\n",
       "             North-Western         70\n",
       "             North Caucasus        69\n",
       "             St. Petersburg        39\n",
       "             Far East              20\n",
       "Name: regional_location, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVar='Russia'\n",
    "\n",
    "df2 = df[df['country'] == testVar]\n",
    "df2.groupby('survey_year')['regional_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>geometry.type</th>\n",
       "      <th>geometry.coordinates</th>\n",
       "      <th>properties.shapeName</th>\n",
       "      <th>properties.Level</th>\n",
       "      <th>properties.shapeISO</th>\n",
       "      <th>properties.shapeID</th>\n",
       "      <th>properties.shapeGroup</th>\n",
       "      <th>properties.shapeType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[85.1159569, 54.43783], [85.0334526, 54.4089...</td>\n",
       "      <td>Altai Krai</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-ALT</td>\n",
       "      <td>RUS-ADM1-28173009B49567218</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>[[[[42.442326, 54.8253986], [42.4073558, 54.84...</td>\n",
       "      <td>Republic of Mordovia</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-MO</td>\n",
       "      <td>RUS-ADM1-28173009B40201491</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[37.2687091, 54.8418015], [37.2565636, 54.83...</td>\n",
       "      <td>Tula Oblast</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-TUL</td>\n",
       "      <td>RUS-ADM1-28173009B92489997</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[62.0610577, 56.1308206], [62.070083, 56.129...</td>\n",
       "      <td>Kurgan Oblast</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-KGN</td>\n",
       "      <td>RUS-ADM1-28173009B91354212</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[44.8479393, 43.5655338], [44.8277321, 43.55...</td>\n",
       "      <td>Ingushetia</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-IN</td>\n",
       "      <td>RUS-ADM1-28173009B89166101</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Feature</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>[[[[47.6840096, 43.9085911], [47.6834087, 43.9...</td>\n",
       "      <td>Dagestan</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-DA</td>\n",
       "      <td>RUS-ADM1-28173009B43574749</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Feature</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>[[[[19.648615891827397, 54.4532277146658], [19...</td>\n",
       "      <td>Kaliningrad</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-KGD</td>\n",
       "      <td>RUS-ADM1-28173009B12217295</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[50.7681628, 51.7730366], [50.871413, 51.753...</td>\n",
       "      <td>Orenburg Oblast</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-ORE</td>\n",
       "      <td>RUS-ADM1-28173009B57910928</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Feature</td>\n",
       "      <td>MultiPolygon</td>\n",
       "      <td>[[[[132.4063493, 44.545623], [132.4066543, 44....</td>\n",
       "      <td>Primorsky Krai</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-PRI</td>\n",
       "      <td>RUS-ADM1-28173009B5071071</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[57.4062372, 56.3426599], [57.3965811, 56.34...</td>\n",
       "      <td>Bashkortostan</td>\n",
       "      <td>ADM1</td>\n",
       "      <td>RU-BA</td>\n",
       "      <td>RUS-ADM1-28173009B50380208</td>\n",
       "      <td>RUS</td>\n",
       "      <td>ADM1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type geometry.type                               geometry.coordinates  \\\n",
       "0   Feature       Polygon  [[[85.1159569, 54.43783], [85.0334526, 54.4089...   \n",
       "1   Feature  MultiPolygon  [[[[42.442326, 54.8253986], [42.4073558, 54.84...   \n",
       "2   Feature       Polygon  [[[37.2687091, 54.8418015], [37.2565636, 54.83...   \n",
       "3   Feature       Polygon  [[[62.0610577, 56.1308206], [62.070083, 56.129...   \n",
       "4   Feature       Polygon  [[[44.8479393, 43.5655338], [44.8277321, 43.55...   \n",
       "..      ...           ...                                                ...   \n",
       "78  Feature  MultiPolygon  [[[[47.6840096, 43.9085911], [47.6834087, 43.9...   \n",
       "79  Feature  MultiPolygon  [[[[19.648615891827397, 54.4532277146658], [19...   \n",
       "80  Feature       Polygon  [[[50.7681628, 51.7730366], [50.871413, 51.753...   \n",
       "81  Feature  MultiPolygon  [[[[132.4063493, 44.545623], [132.4066543, 44....   \n",
       "82  Feature       Polygon  [[[57.4062372, 56.3426599], [57.3965811, 56.34...   \n",
       "\n",
       "    properties.shapeName properties.Level properties.shapeISO  \\\n",
       "0             Altai Krai             ADM1              RU-ALT   \n",
       "1   Republic of Mordovia             ADM1               RU-MO   \n",
       "2            Tula Oblast             ADM1              RU-TUL   \n",
       "3          Kurgan Oblast             ADM1              RU-KGN   \n",
       "4             Ingushetia             ADM1               RU-IN   \n",
       "..                   ...              ...                 ...   \n",
       "78              Dagestan             ADM1               RU-DA   \n",
       "79           Kaliningrad             ADM1              RU-KGD   \n",
       "80       Orenburg Oblast             ADM1              RU-ORE   \n",
       "81        Primorsky Krai             ADM1              RU-PRI   \n",
       "82         Bashkortostan             ADM1               RU-BA   \n",
       "\n",
       "            properties.shapeID properties.shapeGroup properties.shapeType  \n",
       "0   RUS-ADM1-28173009B49567218                   RUS                 ADM1  \n",
       "1   RUS-ADM1-28173009B40201491                   RUS                 ADM1  \n",
       "2   RUS-ADM1-28173009B92489997                   RUS                 ADM1  \n",
       "3   RUS-ADM1-28173009B91354212                   RUS                 ADM1  \n",
       "4   RUS-ADM1-28173009B89166101                   RUS                 ADM1  \n",
       "..                         ...                   ...                  ...  \n",
       "78  RUS-ADM1-28173009B43574749                   RUS                 ADM1  \n",
       "79  RUS-ADM1-28173009B12217295                   RUS                 ADM1  \n",
       "80  RUS-ADM1-28173009B57910928                   RUS                 ADM1  \n",
       "81   RUS-ADM1-28173009B5071071                   RUS                 ADM1  \n",
       "82  RUS-ADM1-28173009B50380208                   RUS                 ADM1  \n",
       "\n",
       "[83 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = load_boundary(countries.at[countries.loc[countries['country']==testVar].index[0], 'iso3'])\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Prepare Data for Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'qdate_s' : 'qdate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ensure all the variables are as expected and that we have all of the variables we would like to be collecting\u001b[39;00m\n\u001b[1;32m      2\u001b[0m vars_list \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpewQVDict.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Variable Listing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(vars_list[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mset\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns))) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ensure all the variables are as expected and that we have all of the variables we would like to be collecting\n",
    "vars_list = pd.read_excel(\"pewQVDict.xlsx\", sheet_name=\"Final Variable Listing\")\n",
    "\n",
    "assert len(set(vars_list['variable_name']).difference(set(df.columns))) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Geocoded Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data_final/pew.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrangle",
   "language": "python",
   "name": "wrangle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
