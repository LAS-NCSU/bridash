{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Used to grab URLs and direct people to certain websites. \n",
    "import urllib.request\n",
    "import urllib\n",
    "\n",
    "# Beautiful Soup used for scrapping from the front end of website. Think scrapping paragraphs to build features. \n",
    "import bs4\n",
    "\n",
    "# Selenium used for webcrawling and jumping to new pages, site navigation. You can also use for scrapping. \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Scrapy used for scrapping \n",
    "# popular resource, but not used here. \n",
    "# import scrapy \n",
    "\n",
    "# utilized to conduct parsing of strings. \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup\n",
    "\n",
    "Other Resources: \n",
    "- [Look for Step 3: Parse HTML with BS](https://realpython.com/beautiful-soup-web-scraper-python/#step-2-scrape-html-content-from-a-page)\n",
    "- [DataQuest Tutorial](https://www.dataquest.io/blog/web-scraping-python-using-beautiful-soup/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = \"https://en.wikipedia.org/wiki/Association_football\"\n",
    "req = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find generic information by looking at soup.<tag_of_interest>.text\n",
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more specific of interest pass a tag and a list of parameters find. \n",
    "# For example \"a\" is a link to something and this particular information element has a title with that string denoted.\n",
    "soup.find(\"a\", {\"title\": \"Penalty kick (association football)\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium\n",
    "\n",
    "Purpose: dynamic web crawling and scraping \n",
    "\n",
    "Other Resources: \n",
    "- [Getting started with python automation](https://www.jcchouinard.com/learn-selenium-python-seo-automation/)\n",
    "\n",
    "Note: do NOT follow setup guide for these tools. If you have trouble running I would encourage a session to set up enviornment on AWS VM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver.Chrome('./chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path='/usr/bin/google-chrome', options=options)\n",
    "action = ActionChains(driver)\n",
    "# navigate to site \n",
    "driver.get('https://canarytokens.org/generate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install -y libglib2.0-0=2.50.3-2 \\\n",
    "    libnss3=2:3.26.2-1.1+deb9u1 \\\n",
    "    libgconf-2-4=3.2.6-4+b1 \\\n",
    "    libfontconfig1=2.11.0-6.7+b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo sh -c 'echo \"deb https://dl.google.com/linux/chrome/deb/ stable main\" >> /etc/apt/sources.list.d/google.list'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install google-chrome-stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_type = 'ms_word'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the type of honeytoken of interest\n",
    "action.click(on_element=driver.find_element(\"id\", value=\"dropdown\")).perform()\n",
    "element = driver.find_element(\"xpath\", value=\"//*/li[@data-type=\\\"\" + token_type + \"\\\"]/a/span\")\n",
    "action.click(on_element=element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter in the developer's email. \n",
    "# this is who will get alerted if the token is triggered \n",
    "inputElement = driver.find_element(\"id\", value=\"endpoints\")\n",
    "inputElement.send_keys(\"email@ncsu.edu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter in a memo to remember the purpose of this token \n",
    "inputElement = driver.find_element(\"name\", value=\"memo\")\n",
    "inputElement.send_keys(\"testing hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = driver.find_element(\"id\", value=\"save\")\n",
    "action.click(on_element=save).perform()\n",
    "\n",
    "download = driver.find_element(\"xpath\", value=\"//*[@class=\\\"result ms_word\\\"]/div[1]/div/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this loads a href==None, wait a second a rerun this box. Website is slow to grab. \n",
    "# For real automation we could add a sleep statment to delay processing or dynamically wait. \n",
    "href = download.get_attribute('href')\n",
    "print(href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find matching elements \n",
    "test = \"Confucius Institute for Nigeria\"\n",
    "re.findall(r\"(?:Confucius Institute) (?:for) (.*)\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you can replace elements \n",
    "re.sub(r\"((Confucius Institute) (for|of)) \", \"\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example using the shipping string you had gotten\n",
    "c = '''Shareholdings (%): 70\n",
    "Target no. of container berths: 4\n",
    "Target designed annual handling capacity (TEU): 77,200\n",
    "Water depth (m): 6.4\n",
    "Target no. of bulk berths: 4\n",
    "Target designed annual handling capacity (tons): 4,200,000\n",
    "Water depth (m): 6.4'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"These are shareholdings % \" + str(re.findall(r'(?:Shareholdings \\(%\\): )(.*)', c)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets look at container berths: \n",
    "re.findall(r'(?:Target no. of container berths: )(.*)', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But lets get just the number to store in the dataset  \n",
    "int(re.findall(r'(?:Target no. of container berths: )(.*)', c)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
